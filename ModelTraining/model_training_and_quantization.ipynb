{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training and Quantization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, we will use the dataset created in the previous stage to train a model to detect persons based on CSI data. Then, we will optimize and export it for execution in real time using a ESP32 board.\n",
        "\n",
        "This notebook is divided into four parts:\n",
        "1) **Data importing and feature engineering** (from our previously created dataset)\n",
        "2) **Model training using Tensorflow** (no expensive GPU required!)\n",
        "3) **Model quantization using LiteRT** (for minimizing model size and inference time)\n",
        "4) **Model convertion to C data array** (for execution on the ESP32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OvKTcc75bXt"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_ChvElLf5Avc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import callbacks\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deKb0IvS5KXE",
        "outputId": "62284afa-8ab3-4779-c3ae-a94b1ac434df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Make numpy values easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "# Let's check our Tensorflow version\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf6QZLqt6u4h"
      },
      "source": [
        "## Data importing and feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's import our train and test datasets. As a reminder, they are already separated from each other to prevent data contamination during the sliding window procedure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lMqnyDmu61WE"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_parquet(\"../DataProcessing/5_datasets/TRAIN_dataset_v2.parquet\")\n",
        "df_test = pd.read_parquet(\"../DataProcessing/5_datasets/TEST_dataset_v2.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>1x1</th>\n",
              "      <th>1x2</th>\n",
              "      <th>1x3</th>\n",
              "      <th>1x4</th>\n",
              "      <th>1x5</th>\n",
              "      <th>1x6</th>\n",
              "      <th>1x7</th>\n",
              "      <th>1x8</th>\n",
              "      <th>1x9</th>\n",
              "      <th>...</th>\n",
              "      <th>100x43</th>\n",
              "      <th>100x44</th>\n",
              "      <th>100x45</th>\n",
              "      <th>100x46</th>\n",
              "      <th>100x47</th>\n",
              "      <th>100x48</th>\n",
              "      <th>100x49</th>\n",
              "      <th>100x50</th>\n",
              "      <th>100x51</th>\n",
              "      <th>100x52</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-51.705446</td>\n",
              "      <td>-51.423908</td>\n",
              "      <td>-51.496811</td>\n",
              "      <td>-51.510120</td>\n",
              "      <td>-51.557132</td>\n",
              "      <td>-51.535879</td>\n",
              "      <td>-51.565779</td>\n",
              "      <td>-51.570532</td>\n",
              "      <td>-51.630636</td>\n",
              "      <td>...</td>\n",
              "      <td>-56.989539</td>\n",
              "      <td>-56.998313</td>\n",
              "      <td>-56.958502</td>\n",
              "      <td>-56.939802</td>\n",
              "      <td>-56.921101</td>\n",
              "      <td>-56.871816</td>\n",
              "      <td>-56.838084</td>\n",
              "      <td>-56.855117</td>\n",
              "      <td>-56.872150</td>\n",
              "      <td>-56.863376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-53.126589</td>\n",
              "      <td>-52.897802</td>\n",
              "      <td>-52.951718</td>\n",
              "      <td>-52.957503</td>\n",
              "      <td>-52.940708</td>\n",
              "      <td>-52.973299</td>\n",
              "      <td>-52.996578</td>\n",
              "      <td>-53.063365</td>\n",
              "      <td>-53.097971</td>\n",
              "      <td>...</td>\n",
              "      <td>-56.826967</td>\n",
              "      <td>-56.888419</td>\n",
              "      <td>-56.874295</td>\n",
              "      <td>-56.882567</td>\n",
              "      <td>-56.863333</td>\n",
              "      <td>-56.844099</td>\n",
              "      <td>-56.858878</td>\n",
              "      <td>-56.841845</td>\n",
              "      <td>-56.856624</td>\n",
              "      <td>-56.871403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-52.180428</td>\n",
              "      <td>-52.346506</td>\n",
              "      <td>-52.346735</td>\n",
              "      <td>-52.429096</td>\n",
              "      <td>-52.440990</td>\n",
              "      <td>-52.502765</td>\n",
              "      <td>-52.546891</td>\n",
              "      <td>-52.593040</td>\n",
              "      <td>-52.628934</td>\n",
              "      <td>...</td>\n",
              "      <td>-55.518491</td>\n",
              "      <td>-55.544820</td>\n",
              "      <td>-55.522918</td>\n",
              "      <td>-55.550747</td>\n",
              "      <td>-55.578576</td>\n",
              "      <td>-55.548514</td>\n",
              "      <td>-55.466558</td>\n",
              "      <td>-55.436496</td>\n",
              "      <td>-55.454657</td>\n",
              "      <td>-55.431944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-52.812095</td>\n",
              "      <td>-52.877571</td>\n",
              "      <td>-52.899397</td>\n",
              "      <td>-52.964835</td>\n",
              "      <td>-52.927434</td>\n",
              "      <td>-52.966386</td>\n",
              "      <td>-52.994210</td>\n",
              "      <td>-53.025664</td>\n",
              "      <td>-53.050129</td>\n",
              "      <td>...</td>\n",
              "      <td>-56.101104</td>\n",
              "      <td>-56.097376</td>\n",
              "      <td>-56.039618</td>\n",
              "      <td>-55.969037</td>\n",
              "      <td>-55.953594</td>\n",
              "      <td>-55.941600</td>\n",
              "      <td>-55.929607</td>\n",
              "      <td>-55.846010</td>\n",
              "      <td>-55.818094</td>\n",
              "      <td>-55.777377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-52.203216</td>\n",
              "      <td>-51.991086</td>\n",
              "      <td>-52.103481</td>\n",
              "      <td>-52.072961</td>\n",
              "      <td>-52.093341</td>\n",
              "      <td>-52.076188</td>\n",
              "      <td>-52.140729</td>\n",
              "      <td>-52.189136</td>\n",
              "      <td>-52.184420</td>\n",
              "      <td>...</td>\n",
              "      <td>-56.145657</td>\n",
              "      <td>-56.176241</td>\n",
              "      <td>-56.153277</td>\n",
              "      <td>-56.179606</td>\n",
              "      <td>-56.156643</td>\n",
              "      <td>-56.187227</td>\n",
              "      <td>-56.154775</td>\n",
              "      <td>-56.168080</td>\n",
              "      <td>-56.205064</td>\n",
              "      <td>-56.191338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-72.377810</td>\n",
              "      <td>-72.377810</td>\n",
              "      <td>-72.517505</td>\n",
              "      <td>-72.521948</td>\n",
              "      <td>-72.524614</td>\n",
              "      <td>-72.481069</td>\n",
              "      <td>-72.546801</td>\n",
              "      <td>-72.558891</td>\n",
              "      <td>-72.568294</td>\n",
              "      <td>...</td>\n",
              "      <td>-73.800800</td>\n",
              "      <td>-73.821193</td>\n",
              "      <td>-73.892296</td>\n",
              "      <td>-73.912689</td>\n",
              "      <td>-73.983791</td>\n",
              "      <td>-74.004185</td>\n",
              "      <td>-74.037290</td>\n",
              "      <td>-74.070395</td>\n",
              "      <td>-74.103500</td>\n",
              "      <td>-74.083466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-72.672382</td>\n",
              "      <td>-72.672382</td>\n",
              "      <td>-72.672382</td>\n",
              "      <td>-72.647173</td>\n",
              "      <td>-72.731509</td>\n",
              "      <td>-72.704849</td>\n",
              "      <td>-72.736653</td>\n",
              "      <td>-72.739661</td>\n",
              "      <td>-72.760530</td>\n",
              "      <td>...</td>\n",
              "      <td>-74.016193</td>\n",
              "      <td>-74.038970</td>\n",
              "      <td>-74.062372</td>\n",
              "      <td>-74.104192</td>\n",
              "      <td>-74.102771</td>\n",
              "      <td>-74.054800</td>\n",
              "      <td>-74.006829</td>\n",
              "      <td>-73.958858</td>\n",
              "      <td>-73.910887</td>\n",
              "      <td>-73.886064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-73.016966</td>\n",
              "      <td>-72.811591</td>\n",
              "      <td>-72.959830</td>\n",
              "      <td>-72.982882</td>\n",
              "      <td>-73.077856</td>\n",
              "      <td>-73.073553</td>\n",
              "      <td>-73.094410</td>\n",
              "      <td>-73.061929</td>\n",
              "      <td>-73.079443</td>\n",
              "      <td>...</td>\n",
              "      <td>-72.806474</td>\n",
              "      <td>-72.828655</td>\n",
              "      <td>-72.916206</td>\n",
              "      <td>-72.990956</td>\n",
              "      <td>-73.006063</td>\n",
              "      <td>-72.963709</td>\n",
              "      <td>-72.978816</td>\n",
              "      <td>-73.055776</td>\n",
              "      <td>-73.015347</td>\n",
              "      <td>-73.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-73.954359</td>\n",
              "      <td>-73.851209</td>\n",
              "      <td>-74.123166</td>\n",
              "      <td>-74.110712</td>\n",
              "      <td>-74.103240</td>\n",
              "      <td>-74.098258</td>\n",
              "      <td>-74.094700</td>\n",
              "      <td>-74.092032</td>\n",
              "      <td>-74.117538</td>\n",
              "      <td>...</td>\n",
              "      <td>-75.004124</td>\n",
              "      <td>-75.035671</td>\n",
              "      <td>-75.003684</td>\n",
              "      <td>-74.963917</td>\n",
              "      <td>-74.955697</td>\n",
              "      <td>-74.947476</td>\n",
              "      <td>-74.939256</td>\n",
              "      <td>-74.899489</td>\n",
              "      <td>-74.859722</td>\n",
              "      <td>-74.819955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-72.970411</td>\n",
              "      <td>-73.149691</td>\n",
              "      <td>-73.209451</td>\n",
              "      <td>-73.133425</td>\n",
              "      <td>-73.151434</td>\n",
              "      <td>-73.163440</td>\n",
              "      <td>-73.172016</td>\n",
              "      <td>-73.178447</td>\n",
              "      <td>-73.217432</td>\n",
              "      <td>...</td>\n",
              "      <td>-75.211946</td>\n",
              "      <td>-75.220780</td>\n",
              "      <td>-75.229613</td>\n",
              "      <td>-75.226431</td>\n",
              "      <td>-75.285610</td>\n",
              "      <td>-75.344789</td>\n",
              "      <td>-75.372422</td>\n",
              "      <td>-75.454378</td>\n",
              "      <td>-75.414567</td>\n",
              "      <td>-75.464977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>266 rows × 5201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label        1x1        1x2        1x3        1x4        1x5        1x6  \\\n",
              "0      1.0 -51.705446 -51.423908 -51.496811 -51.510120 -51.557132 -51.535879   \n",
              "1      1.0 -53.126589 -52.897802 -52.951718 -52.957503 -52.940708 -52.973299   \n",
              "2      1.0 -52.180428 -52.346506 -52.346735 -52.429096 -52.440990 -52.502765   \n",
              "3      1.0 -52.812095 -52.877571 -52.899397 -52.964835 -52.927434 -52.966386   \n",
              "4      1.0 -52.203216 -51.991086 -52.103481 -52.072961 -52.093341 -52.076188   \n",
              "..     ...        ...        ...        ...        ...        ...        ...   \n",
              "261    0.0 -72.377810 -72.377810 -72.517505 -72.521948 -72.524614 -72.481069   \n",
              "262    0.0 -72.672382 -72.672382 -72.672382 -72.647173 -72.731509 -72.704849   \n",
              "263    0.0 -73.016966 -72.811591 -72.959830 -72.982882 -73.077856 -73.073553   \n",
              "264    0.0 -73.954359 -73.851209 -74.123166 -74.110712 -74.103240 -74.098258   \n",
              "265    0.0 -72.970411 -73.149691 -73.209451 -73.133425 -73.151434 -73.163440   \n",
              "\n",
              "           1x7        1x8        1x9  ...     100x43     100x44     100x45  \\\n",
              "0   -51.565779 -51.570532 -51.630636  ... -56.989539 -56.998313 -56.958502   \n",
              "1   -52.996578 -53.063365 -53.097971  ... -56.826967 -56.888419 -56.874295   \n",
              "2   -52.546891 -52.593040 -52.628934  ... -55.518491 -55.544820 -55.522918   \n",
              "3   -52.994210 -53.025664 -53.050129  ... -56.101104 -56.097376 -56.039618   \n",
              "4   -52.140729 -52.189136 -52.184420  ... -56.145657 -56.176241 -56.153277   \n",
              "..         ...        ...        ...  ...        ...        ...        ...   \n",
              "261 -72.546801 -72.558891 -72.568294  ... -73.800800 -73.821193 -73.892296   \n",
              "262 -72.736653 -72.739661 -72.760530  ... -74.016193 -74.038970 -74.062372   \n",
              "263 -73.094410 -73.061929 -73.079443  ... -72.806474 -72.828655 -72.916206   \n",
              "264 -74.094700 -74.092032 -74.117538  ... -75.004124 -75.035671 -75.003684   \n",
              "265 -73.172016 -73.178447 -73.217432  ... -75.211946 -75.220780 -75.229613   \n",
              "\n",
              "        100x46     100x47     100x48     100x49     100x50     100x51  \\\n",
              "0   -56.939802 -56.921101 -56.871816 -56.838084 -56.855117 -56.872150   \n",
              "1   -56.882567 -56.863333 -56.844099 -56.858878 -56.841845 -56.856624   \n",
              "2   -55.550747 -55.578576 -55.548514 -55.466558 -55.436496 -55.454657   \n",
              "3   -55.969037 -55.953594 -55.941600 -55.929607 -55.846010 -55.818094   \n",
              "4   -56.179606 -56.156643 -56.187227 -56.154775 -56.168080 -56.205064   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "261 -73.912689 -73.983791 -74.004185 -74.037290 -74.070395 -74.103500   \n",
              "262 -74.104192 -74.102771 -74.054800 -74.006829 -73.958858 -73.910887   \n",
              "263 -72.990956 -73.006063 -72.963709 -72.978816 -73.055776 -73.015347   \n",
              "264 -74.963917 -74.955697 -74.947476 -74.939256 -74.899489 -74.859722   \n",
              "265 -75.226431 -75.285610 -75.344789 -75.372422 -75.454378 -75.414567   \n",
              "\n",
              "        100x52  \n",
              "0   -56.863376  \n",
              "1   -56.871403  \n",
              "2   -55.431944  \n",
              "3   -55.777377  \n",
              "4   -56.191338  \n",
              "..         ...  \n",
              "261 -74.083466  \n",
              "262 -73.886064  \n",
              "263 -73.023000  \n",
              "264 -74.819955  \n",
              "265 -75.464977  \n",
              "\n",
              "[266 rows x 5201 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's have a look at how our data looks like!\n",
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two labels: ```0``` represents ambient background noise, and ```1``` represents a person walking between the ESP32 boards.\n",
        "\n",
        "For each dataset sample (row) there are 5200 features, denoting the CSI amplitudes of the 52 Wi-Fi subcarriers during a 100-frame window (a 1-second period)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separating our features from their labels\n",
        "X_train = df_train.copy()\n",
        "y_train = X_train.pop('label')\n",
        "X_test = df_test.copy()\n",
        "y_test = X_test.pop('label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WuScOsrt5HST"
      },
      "outputs": [],
      "source": [
        "# Reshaping our labels for the required input dimensions\n",
        "y_train = y_train.values.reshape(-1, 1)\n",
        "y_test = y_test.values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Those 5200 features are a rather big input for our model, so now let's reduce them to a more manageable size using Principal Component Analisys (PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we will scale the features using the StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7sDTEGe59aA",
        "outputId": "f6937cc2-9917-4a56-8c1b-ad5f5e4ed70d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-62.856 -62.837 -62.866 ... -64.028 -64.    -63.992]\n",
            "[9.659 9.645 9.667 ... 8.251 8.247 8.25 ]\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "print(scaler.mean_)\n",
        "print(scaler.scale_)\n",
        "\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can train and apply our PCA! In this case, we will use a PCA that explains 99% of the data variance. Lower % values will reduce the number of features even more, but potentially result in lower accuracy as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.014  0.014  0.014 ...  0.014  0.014  0.014]\n",
            " [-0.002 -0.002 -0.002 ... -0.001 -0.001 -0.001]\n",
            " [-0.005 -0.005 -0.005 ... -0.002 -0.002 -0.002]\n",
            " ...\n",
            " [-0.009 -0.01  -0.01  ... -0.027 -0.027 -0.027]\n",
            " [-0.005 -0.005 -0.005 ... -0.002 -0.002 -0.002]\n",
            " [ 0.025  0.027  0.026 ...  0.019  0.019  0.019]]\n",
            "(42, 5200)\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(n_components=0.99)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "print(pca.components_)\n",
        "print(pca.components_.shape)\n",
        "\n",
        "input_shape = (X_train.shape[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what's our feature size now, after the PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42,)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From 5200 features per sample to only 42! That's a substantial size reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can export our trained PCA and Scaler for later use in the ESP32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exporting PCA and Scaler for the ESP32\n",
        "\n",
        "n_features = scaler.mean_.size\n",
        "n_frame = n_features // 52\n",
        "n_components = pca.components_.shape[0]\n",
        "\n",
        "# Reshape the parameters\n",
        "scaler_mean = scaler.mean_.reshape(n_frame, 52)\n",
        "scaler_std = scaler.scale_.reshape(n_frame, 52)\n",
        "pca_mean = pca.mean_.reshape(n_frame, 52)\n",
        "pca_components = pca.components_\n",
        "\n",
        "with open('preprocessing.h', 'w') as f:\n",
        "    f.write('#pragma once\\n\\n')\n",
        "\n",
        "    f.write('#define SUBCARRIER_COUNT 52\\n')\n",
        "    f.write(f'#define FRAME_WINDOW_SIZE {n_frame}\\n')\n",
        "    f.write(f'#define PCA_COMPONENTS {n_components}\\n\\n')\n",
        "    \n",
        "    # Define the scaler struct\n",
        "    f.write('typedef struct {\\n')\n",
        "    f.write('  float mean;\\n')\n",
        "    f.write('  float std;\\n')\n",
        "    f.write('} standard_scaler;\\n\\n')\n",
        "\n",
        "    f.write(f'extern const standard_scaler scaler[FRAME_WINDOW_SIZE][SUBCARRIER_COUNT];\\n')\n",
        "    f.write(f'extern const float pca_means[FRAME_WINDOW_SIZE][SUBCARRIER_COUNT];\\n')\n",
        "    f.write(f'extern const float pca_matrix[PCA_COMPONENTS][SUBCARRIER_COUNT * FRAME_WINDOW_SIZE];\\n')\n",
        "\n",
        "with open('preprocessing.c', 'w') as f:\n",
        "    f.write('#include \"preprocessing.h\"\\n\\n')\n",
        "\n",
        "    # Dump scaler params\n",
        "    f.write('const standard_scaler scaler[FRAME_WINDOW_SIZE][SUBCARRIER_COUNT] = {\\n')\n",
        "    for i in range(n_frame):\n",
        "        f.write('    {')\n",
        "        for j in range(52):\n",
        "            mean_val = scaler_mean[i, j]\n",
        "            std_val = scaler_std[i, j]\n",
        "            entry = '' if j == 0 else ' '\n",
        "            entry += f'{{ .mean = {mean_val:.6f}f, .std = {std_val:.6f}f }}'\n",
        "            entry += ',' if j < 51 else ''\n",
        "            f.write(entry)\n",
        "        frame_end = '},\\n' if i < n_frame - 1 else '}\\n'\n",
        "        f.write(frame_end)\n",
        "    f.write('};\\n\\n')\n",
        "\n",
        "    # Dump PCA means\n",
        "    f.write('const float pca_means[FRAME_WINDOW_SIZE][SUBCARRIER_COUNT] = {\\n')\n",
        "    for i in range(n_frame):\n",
        "        entries = '{'\n",
        "        entries += ', '.join(f'{val:.6f}f' for val in pca_mean[i])\n",
        "        row_end = '},\\n' if i < n_frame - 1 else '}\\n'\n",
        "        f.write(f'    {entries}{row_end}')\n",
        "    f.write('};\\n\\n')\n",
        "    \n",
        "    # Dump PCA matrix\n",
        "    f.write('const float pca_matrix[PCA_COMPONENTS][SUBCARRIER_COUNT * FRAME_WINDOW_SIZE] = {\\n')\n",
        "    for idx, comp in enumerate(pca_components):\n",
        "        entries = '{'\n",
        "        entries += ', '.join(f'{val:.6f}f' for val in comp)\n",
        "        row_end = '},\\n' if idx < n_components - 1 else '}\\n'\n",
        "        f.write(f'    {entries}{row_end}')\n",
        "    f.write('};\\n')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The PCA and Scaler are now saved in the ```preprocessing.c``` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have finished our feature engineering, we can finally train our model! Let's use a simple Multilayer Perceptron (MLP), to ensure the best compatibility possible with the ESP32. You could also try to use more complex models, but be sure to check for the [operation compatibility with the ESP-TFLITE-MICRO framework](https://github.com/espressif/esp-tflite-micro/blob/78e5532e682d3863a3c2985c3a74eed0a9ebaa61/tensorflow/lite/micro/micro_mutable_op_resolver.h#L45)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "We will use an input layer with a number of neurons equal to the number of features, then add hidden layers dividing the number of neurons for 2 until we have our output.\n",
        "\n",
        "We will also add Dropout layers in between each fully connected layer to reduce the chance of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1UlDFhMYkwKw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\samuk\\anaconda3\\envs\\sbrc\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(42, activation='relu',  input_shape=input_shape),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(32, activation='relu',  input_shape=input_shape),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(16, activation='relu',  input_shape=input_shape),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(8, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(4, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(2, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VQG1h1-v-hc",
        "outputId": "15f58b48-d689-412d-aec1-d37bf4d55c7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,376</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │         \u001b[38;5;34m1,806\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,376\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,895</span> (15.21 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,895\u001b[0m (15.21 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,895</span> (15.21 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,895\u001b[0m (15.21 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we train the model for 200 epochs, and save the model with the lowest train loss (which is correlated to the highest accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI9XG8KF3TVF",
        "outputId": "82e93386-ba4c-4121-d67d-1a1bd02a5be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 2s/step - binary_accuracy: 0.5938 - loss: 0.7724\n",
            "Epoch 1: loss improved from inf to 0.70171, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - binary_accuracy: 0.5734 - loss: 0.7099 - val_binary_accuracy: 0.5977 - val_loss: 0.6852\n",
            "Epoch 2/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.5938 - loss: 0.7311\n",
            "Epoch 2: loss improved from 0.70171 to 0.66381, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.5779 - loss: 0.6811 - val_binary_accuracy: 0.7594 - val_loss: 0.6301\n",
            "Epoch 3/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.7188 - loss: 0.6204\n",
            "Epoch 3: loss improved from 0.66381 to 0.64496, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.6276 - loss: 0.6410 - val_binary_accuracy: 0.8421 - val_loss: 0.5850\n",
            "Epoch 4/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.6250 - loss: 0.5517\n",
            "Epoch 4: loss improved from 0.64496 to 0.60102, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.6385 - loss: 0.6121 - val_binary_accuracy: 0.8872 - val_loss: 0.5276\n",
            "Epoch 5/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.7500 - loss: 0.5529\n",
            "Epoch 5: loss improved from 0.60102 to 0.55466, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.6905 - loss: 0.5751 - val_binary_accuracy: 0.9135 - val_loss: 0.4684\n",
            "Epoch 6/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.6562 - loss: 0.5767\n",
            "Epoch 6: loss improved from 0.55466 to 0.51833, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.7201 - loss: 0.5335 - val_binary_accuracy: 0.9211 - val_loss: 0.4347\n",
            "Epoch 7/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.7812 - loss: 0.5392\n",
            "Epoch 7: loss improved from 0.51833 to 0.48242, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.7916 - loss: 0.4918 - val_binary_accuracy: 0.9173 - val_loss: 0.4016\n",
            "Epoch 8/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.7188 - loss: 0.5167\n",
            "Epoch 8: loss improved from 0.48242 to 0.47016, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8034 - loss: 0.4596 - val_binary_accuracy: 0.9211 - val_loss: 0.3751\n",
            "Epoch 9/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.7812 - loss: 0.4173\n",
            "Epoch 9: loss improved from 0.47016 to 0.43368, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8235 - loss: 0.4503 - val_binary_accuracy: 0.9398 - val_loss: 0.3399\n",
            "Epoch 10/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.7812 - loss: 0.5287\n",
            "Epoch 10: loss improved from 0.43368 to 0.40241, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8622 - loss: 0.4378 - val_binary_accuracy: 0.9248 - val_loss: 0.3411\n",
            "Epoch 11/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.3718\n",
            "Epoch 11: loss improved from 0.40241 to 0.38560, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8673 - loss: 0.3943 - val_binary_accuracy: 0.9248 - val_loss: 0.3252\n",
            "Epoch 12/200\n",
            "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8822 - loss: 0.3863 \n",
            "Epoch 12: loss improved from 0.38560 to 0.37540, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8821 - loss: 0.3846 - val_binary_accuracy: 0.9361 - val_loss: 0.2986\n",
            "Epoch 13/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.2359\n",
            "Epoch 13: loss improved from 0.37540 to 0.33292, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9202 - loss: 0.3192 - val_binary_accuracy: 0.9474 - val_loss: 0.2818\n",
            "Epoch 14/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.8125 - loss: 0.3339\n",
            "Epoch 14: loss improved from 0.33292 to 0.32674, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9075 - loss: 0.3190 - val_binary_accuracy: 0.9398 - val_loss: 0.2738\n",
            "Epoch 15/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.3535\n",
            "Epoch 15: loss improved from 0.32674 to 0.31560, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8925 - loss: 0.3147 - val_binary_accuracy: 0.9436 - val_loss: 0.2501\n",
            "Epoch 16/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9375 - loss: 0.2617\n",
            "Epoch 16: loss improved from 0.31560 to 0.28313, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9196 - loss: 0.2807 - val_binary_accuracy: 0.9699 - val_loss: 0.2174\n",
            "Epoch 17/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8438 - loss: 0.3400\n",
            "Epoch 17: loss did not improve from 0.28313\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9093 - loss: 0.2867 - val_binary_accuracy: 0.9699 - val_loss: 0.2080\n",
            "Epoch 18/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.2434\n",
            "Epoch 18: loss improved from 0.28313 to 0.26543, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9270 - loss: 0.2608 - val_binary_accuracy: 0.9737 - val_loss: 0.1972\n",
            "Epoch 19/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.2665\n",
            "Epoch 19: loss improved from 0.26543 to 0.25258, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9314 - loss: 0.2517 - val_binary_accuracy: 0.9511 - val_loss: 0.2039\n",
            "Epoch 20/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8750 - loss: 0.2878\n",
            "Epoch 20: loss improved from 0.25258 to 0.23858, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9043 - loss: 0.2579 - val_binary_accuracy: 0.9737 - val_loss: 0.1690\n",
            "Epoch 21/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.1465\n",
            "Epoch 21: loss improved from 0.23858 to 0.21751, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9417 - loss: 0.2094 - val_binary_accuracy: 0.9699 - val_loss: 0.1678\n",
            "Epoch 22/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8750 - loss: 0.2967\n",
            "Epoch 22: loss did not improve from 0.21751\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9191 - loss: 0.2302 - val_binary_accuracy: 0.9887 - val_loss: 0.1401\n",
            "Epoch 23/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.1474\n",
            "Epoch 23: loss improved from 0.21751 to 0.20327, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9283 - loss: 0.2071 - val_binary_accuracy: 0.9887 - val_loss: 0.1321\n",
            "Epoch 24/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9375 - loss: 0.1505\n",
            "Epoch 24: loss improved from 0.20327 to 0.18702, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9374 - loss: 0.1843 - val_binary_accuracy: 0.9774 - val_loss: 0.1429\n",
            "Epoch 25/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.1544\n",
            "Epoch 25: loss improved from 0.18702 to 0.16408, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9585 - loss: 0.1558 - val_binary_accuracy: 0.9774 - val_loss: 0.1231\n",
            "Epoch 26/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.1476\n",
            "Epoch 26: loss did not improve from 0.16408\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9122 - loss: 0.2124 - val_binary_accuracy: 0.9737 - val_loss: 0.1364\n",
            "Epoch 27/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.1500\n",
            "Epoch 27: loss did not improve from 0.16408\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9488 - loss: 0.1568 - val_binary_accuracy: 0.9774 - val_loss: 0.1133\n",
            "Epoch 28/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.1780\n",
            "Epoch 28: loss did not improve from 0.16408\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9305 - loss: 0.1767 - val_binary_accuracy: 0.9812 - val_loss: 0.1056\n",
            "Epoch 29/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - binary_accuracy: 0.9062 - loss: 0.1820\n",
            "Epoch 29: loss did not improve from 0.16408\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9319 - loss: 0.1695 - val_binary_accuracy: 0.9887 - val_loss: 0.0912\n",
            "Epoch 30/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9062 - loss: 0.2009\n",
            "Epoch 30: loss improved from 0.16408 to 0.15290, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9224 - loss: 0.1736 - val_binary_accuracy: 0.9925 - val_loss: 0.0812\n",
            "Epoch 31/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.1408\n",
            "Epoch 31: loss improved from 0.15290 to 0.14182, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9397 - loss: 0.1474 - val_binary_accuracy: 0.9925 - val_loss: 0.0791\n",
            "Epoch 32/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8750 - loss: 0.1810\n",
            "Epoch 32: loss did not improve from 0.14182\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9368 - loss: 0.1421 - val_binary_accuracy: 0.9925 - val_loss: 0.0773\n",
            "Epoch 33/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9375 - loss: 0.1459\n",
            "Epoch 33: loss improved from 0.14182 to 0.13892, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9458 - loss: 0.1297 - val_binary_accuracy: 0.9887 - val_loss: 0.0711\n",
            "Epoch 34/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0846\n",
            "Epoch 34: loss did not improve from 0.13892\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9409 - loss: 0.1328 - val_binary_accuracy: 0.9887 - val_loss: 0.0589\n",
            "Epoch 35/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8750 - loss: 0.2010\n",
            "Epoch 35: loss improved from 0.13892 to 0.12106, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9427 - loss: 0.1222 - val_binary_accuracy: 0.9887 - val_loss: 0.0533\n",
            "Epoch 36/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.1014\n",
            "Epoch 36: loss improved from 0.12106 to 0.09764, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9563 - loss: 0.0914 - val_binary_accuracy: 0.9774 - val_loss: 0.0670\n",
            "Epoch 37/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9375 - loss: 0.0862\n",
            "Epoch 37: loss did not improve from 0.09764\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9422 - loss: 0.1107 - val_binary_accuracy: 0.9812 - val_loss: 0.0661\n",
            "Epoch 38/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8750 - loss: 0.1518\n",
            "Epoch 38: loss did not improve from 0.09764\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9160 - loss: 0.1374 - val_binary_accuracy: 0.9887 - val_loss: 0.0467\n",
            "Epoch 39/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.8750 - loss: 0.1761\n",
            "Epoch 39: loss did not improve from 0.09764\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9340 - loss: 0.1162 - val_binary_accuracy: 0.9887 - val_loss: 0.0448\n",
            "Epoch 40/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.1004\n",
            "Epoch 40: loss did not improve from 0.09764\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9504 - loss: 0.1065 - val_binary_accuracy: 0.9812 - val_loss: 0.0518\n",
            "Epoch 41/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0630\n",
            "Epoch 41: loss did not improve from 0.09764\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9480 - loss: 0.0968 - val_binary_accuracy: 0.9850 - val_loss: 0.0465\n",
            "Epoch 42/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0577\n",
            "Epoch 42: loss did not improve from 0.09764\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9396 - loss: 0.1005 - val_binary_accuracy: 0.9925 - val_loss: 0.0303\n",
            "Epoch 43/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 1.0000 - loss: 0.0141\n",
            "Epoch 43: loss improved from 0.09764 to 0.09165, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9446 - loss: 0.0944 - val_binary_accuracy: 0.9925 - val_loss: 0.0291\n",
            "Epoch 44/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9062 - loss: 0.1092\n",
            "Epoch 44: loss did not improve from 0.09165\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9268 - loss: 0.1112 - val_binary_accuracy: 0.9925 - val_loss: 0.0358\n",
            "Epoch 45/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.9375 - loss: 0.0729\n",
            "Epoch 45: loss improved from 0.09165 to 0.09149, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9472 - loss: 0.0884 - val_binary_accuracy: 0.9887 - val_loss: 0.0301\n",
            "Epoch 46/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0969\n",
            "Epoch 46: loss improved from 0.09149 to 0.08482, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9579 - loss: 0.0773 - val_binary_accuracy: 0.9925 - val_loss: 0.0248\n",
            "Epoch 47/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.0736\n",
            "Epoch 47: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9472 - loss: 0.0927 - val_binary_accuracy: 0.9925 - val_loss: 0.0277\n",
            "Epoch 48/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0370\n",
            "Epoch 48: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9584 - loss: 0.0852 - val_binary_accuracy: 0.9925 - val_loss: 0.0257\n",
            "Epoch 49/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0669\n",
            "Epoch 49: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9479 - loss: 0.0912 - val_binary_accuracy: 0.9925 - val_loss: 0.0241\n",
            "Epoch 50/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9062 - loss: 0.1231\n",
            "Epoch 50: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9338 - loss: 0.1100 - val_binary_accuracy: 0.9925 - val_loss: 0.0252\n",
            "Epoch 51/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0833\n",
            "Epoch 51: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9495 - loss: 0.0835 - val_binary_accuracy: 0.9887 - val_loss: 0.0369\n",
            "Epoch 52/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9062 - loss: 0.1158\n",
            "Epoch 52: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9393 - loss: 0.1093 - val_binary_accuracy: 0.9850 - val_loss: 0.0346\n",
            "Epoch 53/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9062 - loss: 0.3007\n",
            "Epoch 53: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9380 - loss: 0.1264 - val_binary_accuracy: 0.9925 - val_loss: 0.0293\n",
            "Epoch 54/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0931\n",
            "Epoch 54: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9326 - loss: 0.1110 - val_binary_accuracy: 0.9887 - val_loss: 0.0267\n",
            "Epoch 55/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0553\n",
            "Epoch 55: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9399 - loss: 0.0999 - val_binary_accuracy: 0.9925 - val_loss: 0.0242\n",
            "Epoch 56/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.1264\n",
            "Epoch 56: loss did not improve from 0.08482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9433 - loss: 0.1058 - val_binary_accuracy: 0.9925 - val_loss: 0.0243\n",
            "Epoch 57/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.0969\n",
            "Epoch 57: loss improved from 0.08482 to 0.07948, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9476 - loss: 0.0864 - val_binary_accuracy: 0.9850 - val_loss: 0.0391\n",
            "Epoch 58/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.1535\n",
            "Epoch 58: loss did not improve from 0.07948\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9482 - loss: 0.1114 - val_binary_accuracy: 0.9887 - val_loss: 0.0267\n",
            "Epoch 59/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.1004\n",
            "Epoch 59: loss did not improve from 0.07948\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9479 - loss: 0.0882 - val_binary_accuracy: 0.9962 - val_loss: 0.0217\n",
            "Epoch 60/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9062 - loss: 0.1158\n",
            "Epoch 60: loss did not improve from 0.07948\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9393 - loss: 0.0927 - val_binary_accuracy: 0.9962 - val_loss: 0.0210\n",
            "Epoch 61/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9375 - loss: 0.1088\n",
            "Epoch 61: loss did not improve from 0.07948\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9417 - loss: 0.0924 - val_binary_accuracy: 0.9925 - val_loss: 0.0167\n",
            "Epoch 62/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.9688 - loss: 0.0370\n",
            "Epoch 62: loss did not improve from 0.07948\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9565 - loss: 0.0725 - val_binary_accuracy: 0.9925 - val_loss: 0.0262\n",
            "Epoch 63/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.1031\n",
            "Epoch 63: loss did not improve from 0.07948\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9554 - loss: 0.0832 - val_binary_accuracy: 0.9887 - val_loss: 0.0345\n",
            "Epoch 64/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0638\n",
            "Epoch 64: loss improved from 0.07948 to 0.07667, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9578 - loss: 0.0707 - val_binary_accuracy: 0.9887 - val_loss: 0.0326\n",
            "Epoch 65/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - binary_accuracy: 1.0000 - loss: 0.0088\n",
            "Epoch 65: loss improved from 0.07667 to 0.07520, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9567 - loss: 0.0704 - val_binary_accuracy: 0.9925 - val_loss: 0.0292\n",
            "Epoch 66/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9062 - loss: 0.1001\n",
            "Epoch 66: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9410 - loss: 0.0848 - val_binary_accuracy: 0.9925 - val_loss: 0.0276\n",
            "Epoch 67/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0459\n",
            "Epoch 67: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9459 - loss: 0.0824 - val_binary_accuracy: 0.9887 - val_loss: 0.0291\n",
            "Epoch 68/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0851\n",
            "Epoch 68: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9464 - loss: 0.0911 - val_binary_accuracy: 0.9925 - val_loss: 0.0266\n",
            "Epoch 69/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.8750 - loss: 0.1412\n",
            "Epoch 69: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9377 - loss: 0.0970 - val_binary_accuracy: 0.9925 - val_loss: 0.0268\n",
            "Epoch 70/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0512\n",
            "Epoch 70: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9461 - loss: 0.0873 - val_binary_accuracy: 0.9887 - val_loss: 0.0377\n",
            "Epoch 71/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0481\n",
            "Epoch 71: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9374 - loss: 0.1020 - val_binary_accuracy: 0.9887 - val_loss: 0.0351\n",
            "Epoch 72/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8750 - loss: 0.1777\n",
            "Epoch 72: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9338 - loss: 0.0975 - val_binary_accuracy: 0.9887 - val_loss: 0.0463\n",
            "Epoch 73/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9062 - loss: 0.1291\n",
            "Epoch 73: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9473 - loss: 0.0879 - val_binary_accuracy: 0.9850 - val_loss: 0.0554\n",
            "Epoch 74/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0892\n",
            "Epoch 74: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9509 - loss: 0.0894 - val_binary_accuracy: 0.9850 - val_loss: 0.0479\n",
            "Epoch 75/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0648\n",
            "Epoch 75: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9485 - loss: 0.0941 - val_binary_accuracy: 0.9925 - val_loss: 0.0322\n",
            "Epoch 76/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.9375 - loss: 0.0822\n",
            "Epoch 76: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9528 - loss: 0.0832 - val_binary_accuracy: 0.9850 - val_loss: 0.0509\n",
            "Epoch 77/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0327\n",
            "Epoch 77: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9572 - loss: 0.0734 - val_binary_accuracy: 0.9887 - val_loss: 0.0382\n",
            "Epoch 78/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9062 - loss: 0.1408\n",
            "Epoch 78: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9286 - loss: 0.1008 - val_binary_accuracy: 0.9887 - val_loss: 0.0372\n",
            "Epoch 79/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9688 - loss: 0.0478\n",
            "Epoch 79: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9379 - loss: 0.0937 - val_binary_accuracy: 0.9925 - val_loss: 0.0367\n",
            "Epoch 80/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0363\n",
            "Epoch 80: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9555 - loss: 0.0745 - val_binary_accuracy: 0.9887 - val_loss: 0.0433\n",
            "Epoch 81/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0784\n",
            "Epoch 81: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9584 - loss: 0.0763 - val_binary_accuracy: 0.9887 - val_loss: 0.0395\n",
            "Epoch 82/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0505\n",
            "Epoch 82: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9577 - loss: 0.0700 - val_binary_accuracy: 0.9850 - val_loss: 0.0370\n",
            "Epoch 83/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0817\n",
            "Epoch 83: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9321 - loss: 0.1028 - val_binary_accuracy: 0.9850 - val_loss: 0.0391\n",
            "Epoch 84/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0102\n",
            "Epoch 84: loss did not improve from 0.07520\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9433 - loss: 0.0937 - val_binary_accuracy: 0.9850 - val_loss: 0.0526\n",
            "Epoch 85/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8438 - loss: 0.1502\n",
            "Epoch 85: loss improved from 0.07520 to 0.07426, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9358 - loss: 0.0816 - val_binary_accuracy: 0.9850 - val_loss: 0.0454\n",
            "Epoch 86/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0487\n",
            "Epoch 86: loss did not improve from 0.07426\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9517 - loss: 0.0763 - val_binary_accuracy: 0.9887 - val_loss: 0.0482\n",
            "Epoch 87/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9688 - loss: 0.0648\n",
            "Epoch 87: loss did not improve from 0.07426\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9476 - loss: 0.0787 - val_binary_accuracy: 0.9850 - val_loss: 0.0488\n",
            "Epoch 88/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0346\n",
            "Epoch 88: loss did not improve from 0.07426\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9555 - loss: 0.0750 - val_binary_accuracy: 0.9850 - val_loss: 0.0533\n",
            "Epoch 89/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0939\n",
            "Epoch 89: loss did not improve from 0.07426\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9477 - loss: 0.0914 - val_binary_accuracy: 0.9812 - val_loss: 0.0511\n",
            "Epoch 90/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0336\n",
            "Epoch 90: loss did not improve from 0.07426\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9614 - loss: 0.0710 - val_binary_accuracy: 0.9812 - val_loss: 0.0590\n",
            "Epoch 91/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0771\n",
            "Epoch 91: loss did not improve from 0.07426\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9524 - loss: 0.0775 - val_binary_accuracy: 0.9850 - val_loss: 0.0580\n",
            "Epoch 92/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0324\n",
            "Epoch 92: loss improved from 0.07426 to 0.06619, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9607 - loss: 0.0584 - val_binary_accuracy: 0.9850 - val_loss: 0.0560\n",
            "Epoch 93/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0848\n",
            "Epoch 93: loss did not improve from 0.06619\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9513 - loss: 0.0786 - val_binary_accuracy: 0.9812 - val_loss: 0.0613\n",
            "Epoch 94/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9062 - loss: 0.0893\n",
            "Epoch 94: loss improved from 0.06619 to 0.06382, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9506 - loss: 0.0724 - val_binary_accuracy: 0.9850 - val_loss: 0.0571\n",
            "Epoch 95/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0478\n",
            "Epoch 95: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9400 - loss: 0.0907 - val_binary_accuracy: 0.9887 - val_loss: 0.0565\n",
            "Epoch 96/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0587\n",
            "Epoch 96: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9495 - loss: 0.0950 - val_binary_accuracy: 0.9887 - val_loss: 0.0507\n",
            "Epoch 97/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.8750 - loss: 0.1193\n",
            "Epoch 97: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9496 - loss: 0.0725 - val_binary_accuracy: 0.9850 - val_loss: 0.0619\n",
            "Epoch 98/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0816\n",
            "Epoch 98: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9492 - loss: 0.0757 - val_binary_accuracy: 0.9887 - val_loss: 0.0497\n",
            "Epoch 99/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0497\n",
            "Epoch 99: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9429 - loss: 0.0929 - val_binary_accuracy: 0.9887 - val_loss: 0.0402\n",
            "Epoch 100/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0790\n",
            "Epoch 100: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9393 - loss: 0.0816 - val_binary_accuracy: 0.9812 - val_loss: 0.0478\n",
            "Epoch 101/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0480\n",
            "Epoch 101: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9503 - loss: 0.0754 - val_binary_accuracy: 0.9925 - val_loss: 0.0372\n",
            "Epoch 102/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0779\n",
            "Epoch 102: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9277 - loss: 0.1086 - val_binary_accuracy: 0.9812 - val_loss: 0.0419\n",
            "Epoch 103/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.8750 - loss: 0.1319\n",
            "Epoch 103: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9404 - loss: 0.0887 - val_binary_accuracy: 0.9887 - val_loss: 0.0482\n",
            "Epoch 104/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0482\n",
            "Epoch 104: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9499 - loss: 0.0709 - val_binary_accuracy: 0.9887 - val_loss: 0.0509\n",
            "Epoch 105/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0929\n",
            "Epoch 105: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9451 - loss: 0.0851 - val_binary_accuracy: 0.9887 - val_loss: 0.0547\n",
            "Epoch 106/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0946\n",
            "Epoch 106: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9276 - loss: 0.0901 - val_binary_accuracy: 0.9887 - val_loss: 0.0458\n",
            "Epoch 107/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0362\n",
            "Epoch 107: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9591 - loss: 0.0618 - val_binary_accuracy: 0.9925 - val_loss: 0.0440\n",
            "Epoch 108/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0908\n",
            "Epoch 108: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9426 - loss: 0.0766 - val_binary_accuracy: 0.9887 - val_loss: 0.0571\n",
            "Epoch 109/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.0991\n",
            "Epoch 109: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9459 - loss: 0.0751 - val_binary_accuracy: 0.9887 - val_loss: 0.0539\n",
            "Epoch 110/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9375 - loss: 0.0907\n",
            "Epoch 110: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9552 - loss: 0.0837 - val_binary_accuracy: 0.9887 - val_loss: 0.0565\n",
            "Epoch 111/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9062 - loss: 0.1202\n",
            "Epoch 111: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9465 - loss: 0.0786 - val_binary_accuracy: 0.9887 - val_loss: 0.0590\n",
            "Epoch 112/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0484\n",
            "Epoch 112: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9446 - loss: 0.0857 - val_binary_accuracy: 0.9887 - val_loss: 0.0611\n",
            "Epoch 113/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0305\n",
            "Epoch 113: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9626 - loss: 0.0605 - val_binary_accuracy: 0.9887 - val_loss: 0.0585\n",
            "Epoch 114/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0904\n",
            "Epoch 114: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9458 - loss: 0.0791 - val_binary_accuracy: 0.9887 - val_loss: 0.0616\n",
            "Epoch 115/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0713\n",
            "Epoch 115: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9525 - loss: 0.0720 - val_binary_accuracy: 0.9850 - val_loss: 0.0679\n",
            "Epoch 116/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 116: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9576 - loss: 0.0655 - val_binary_accuracy: 0.9887 - val_loss: 0.0339\n",
            "Epoch 117/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9375 - loss: 0.0717\n",
            "Epoch 117: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9537 - loss: 0.0816 - val_binary_accuracy: 0.9887 - val_loss: 0.0411\n",
            "Epoch 118/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.0831\n",
            "Epoch 118: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9520 - loss: 0.0785 - val_binary_accuracy: 0.9925 - val_loss: 0.0387\n",
            "Epoch 119/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8438 - loss: 0.1544\n",
            "Epoch 119: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9258 - loss: 0.0995 - val_binary_accuracy: 0.9887 - val_loss: 0.0522\n",
            "Epoch 120/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0827\n",
            "Epoch 120: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9452 - loss: 0.0932 - val_binary_accuracy: 0.9887 - val_loss: 0.0478\n",
            "Epoch 121/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8750 - loss: 0.1256\n",
            "Epoch 121: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9524 - loss: 0.0770 - val_binary_accuracy: 0.9887 - val_loss: 0.0630\n",
            "Epoch 122/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8438 - loss: 0.2338\n",
            "Epoch 122: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9263 - loss: 0.1153 - val_binary_accuracy: 0.9850 - val_loss: 0.0646\n",
            "Epoch 123/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 1.0000 - loss: 0.0378\n",
            "Epoch 123: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9611 - loss: 0.0677 - val_binary_accuracy: 0.9850 - val_loss: 0.0711\n",
            "Epoch 124/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0798\n",
            "Epoch 124: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9527 - loss: 0.0736 - val_binary_accuracy: 0.9887 - val_loss: 0.0691\n",
            "Epoch 125/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.8438 - loss: 0.2316\n",
            "Epoch 125: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9268 - loss: 0.1105 - val_binary_accuracy: 0.9887 - val_loss: 0.0675\n",
            "Epoch 126/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8750 - loss: 0.1417\n",
            "Epoch 126: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9323 - loss: 0.0888 - val_binary_accuracy: 0.9887 - val_loss: 0.0680\n",
            "Epoch 127/200\n",
            "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9648 - loss: 0.0718 \n",
            "Epoch 127: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9631 - loss: 0.0728 - val_binary_accuracy: 0.9887 - val_loss: 0.0664\n",
            "Epoch 128/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0824\n",
            "Epoch 128: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9690 - loss: 0.0644 - val_binary_accuracy: 0.9887 - val_loss: 0.0609\n",
            "Epoch 129/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9375 - loss: 0.1413\n",
            "Epoch 129: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9411 - loss: 0.0832 - val_binary_accuracy: 0.9850 - val_loss: 0.0665\n",
            "Epoch 130/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0471\n",
            "Epoch 130: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9418 - loss: 0.0849 - val_binary_accuracy: 0.9850 - val_loss: 0.0551\n",
            "Epoch 131/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9062 - loss: 0.0968\n",
            "Epoch 131: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9361 - loss: 0.0852 - val_binary_accuracy: 0.9850 - val_loss: 0.0633\n",
            "Epoch 132/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9062 - loss: 0.1148\n",
            "Epoch 132: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9282 - loss: 0.0953 - val_binary_accuracy: 0.9850 - val_loss: 0.0647\n",
            "Epoch 133/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9688 - loss: 0.0829\n",
            "Epoch 133: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9563 - loss: 0.0744 - val_binary_accuracy: 0.9850 - val_loss: 0.0586\n",
            "Epoch 134/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0385\n",
            "Epoch 134: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9644 - loss: 0.0617 - val_binary_accuracy: 0.9850 - val_loss: 0.0662\n",
            "Epoch 135/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.0721\n",
            "Epoch 135: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9384 - loss: 0.0925 - val_binary_accuracy: 0.9887 - val_loss: 0.0521\n",
            "Epoch 136/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0287\n",
            "Epoch 136: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9500 - loss: 0.0661 - val_binary_accuracy: 0.9850 - val_loss: 0.0547\n",
            "Epoch 137/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0445\n",
            "Epoch 137: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9558 - loss: 0.0665 - val_binary_accuracy: 0.9850 - val_loss: 0.0546\n",
            "Epoch 138/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0644\n",
            "Epoch 138: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9543 - loss: 0.0644 - val_binary_accuracy: 0.9850 - val_loss: 0.0547\n",
            "Epoch 139/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0223\n",
            "Epoch 139: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9540 - loss: 0.0777 - val_binary_accuracy: 0.9887 - val_loss: 0.0477\n",
            "Epoch 140/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.1019\n",
            "Epoch 140: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9536 - loss: 0.0732 - val_binary_accuracy: 0.9887 - val_loss: 0.0474\n",
            "Epoch 141/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9375 - loss: 0.0694\n",
            "Epoch 141: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9402 - loss: 0.0822 - val_binary_accuracy: 0.9887 - val_loss: 0.0452\n",
            "Epoch 142/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.1139\n",
            "Epoch 142: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9437 - loss: 0.0842 - val_binary_accuracy: 0.9925 - val_loss: 0.0448\n",
            "Epoch 143/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0724\n",
            "Epoch 143: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9592 - loss: 0.0619 - val_binary_accuracy: 0.9850 - val_loss: 0.0493\n",
            "Epoch 144/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0700\n",
            "Epoch 144: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9594 - loss: 0.0676 - val_binary_accuracy: 0.9887 - val_loss: 0.0520\n",
            "Epoch 145/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0205\n",
            "Epoch 145: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9616 - loss: 0.0645 - val_binary_accuracy: 0.9850 - val_loss: 0.0505\n",
            "Epoch 146/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0697\n",
            "Epoch 146: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9424 - loss: 0.0819 - val_binary_accuracy: 0.9887 - val_loss: 0.0515\n",
            "Epoch 147/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 1.0000 - loss: 0.0378\n",
            "Epoch 147: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9483 - loss: 0.0838 - val_binary_accuracy: 0.9850 - val_loss: 0.0545\n",
            "Epoch 148/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9688 - loss: 0.0644\n",
            "Epoch 148: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9498 - loss: 0.0651 - val_binary_accuracy: 0.9887 - val_loss: 0.0644\n",
            "Epoch 149/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0202\n",
            "Epoch 149: loss did not improve from 0.06382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9413 - loss: 0.0815 - val_binary_accuracy: 0.9812 - val_loss: 0.0722\n",
            "Epoch 150/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9375 - loss: 0.0722\n",
            "Epoch 150: loss improved from 0.06382 to 0.06272, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9476 - loss: 0.0694 - val_binary_accuracy: 0.9850 - val_loss: 0.0640\n",
            "Epoch 151/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9375 - loss: 0.0693\n",
            "Epoch 151: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9540 - loss: 0.0676 - val_binary_accuracy: 0.9887 - val_loss: 0.0625\n",
            "Epoch 152/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.0755\n",
            "Epoch 152: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9411 - loss: 0.0826 - val_binary_accuracy: 0.9925 - val_loss: 0.0451\n",
            "Epoch 153/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0634\n",
            "Epoch 153: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9668 - loss: 0.0596 - val_binary_accuracy: 0.9925 - val_loss: 0.0459\n",
            "Epoch 154/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.0943\n",
            "Epoch 154: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9486 - loss: 0.0715 - val_binary_accuracy: 0.9850 - val_loss: 0.0506\n",
            "Epoch 155/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.8750 - loss: 0.1558\n",
            "Epoch 155: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9397 - loss: 0.0932 - val_binary_accuracy: 0.9850 - val_loss: 0.0608\n",
            "Epoch 156/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.1317\n",
            "Epoch 156: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9435 - loss: 0.0828 - val_binary_accuracy: 0.9850 - val_loss: 0.0656\n",
            "Epoch 157/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.9688 - loss: 0.1023\n",
            "Epoch 157: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9624 - loss: 0.0698 - val_binary_accuracy: 0.9850 - val_loss: 0.0661\n",
            "Epoch 158/200\n",
            "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9296 - loss: 0.0940 \n",
            "Epoch 158: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9300 - loss: 0.0935 - val_binary_accuracy: 0.9850 - val_loss: 0.0665\n",
            "Epoch 159/200\n",
            "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9432 - loss: 0.0735 \n",
            "Epoch 159: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9444 - loss: 0.0736 - val_binary_accuracy: 0.9887 - val_loss: 0.0525\n",
            "Epoch 160/200\n",
            "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9571 - loss: 0.0598 \n",
            "Epoch 160: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9566 - loss: 0.0608 - val_binary_accuracy: 0.9887 - val_loss: 0.0585\n",
            "Epoch 161/200\n",
            "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9470 - loss: 0.0824 \n",
            "Epoch 161: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9467 - loss: 0.0823 - val_binary_accuracy: 0.9850 - val_loss: 0.0706\n",
            "Epoch 162/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0276\n",
            "Epoch 162: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9491 - loss: 0.0863 - val_binary_accuracy: 0.9850 - val_loss: 0.0541\n",
            "Epoch 163/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0254\n",
            "Epoch 163: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9501 - loss: 0.0669 - val_binary_accuracy: 0.9774 - val_loss: 0.0744\n",
            "Epoch 164/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0436\n",
            "Epoch 164: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9561 - loss: 0.0610 - val_binary_accuracy: 0.9812 - val_loss: 0.0688\n",
            "Epoch 165/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.8750 - loss: 0.1422\n",
            "Epoch 165: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9294 - loss: 0.1011 - val_binary_accuracy: 0.9850 - val_loss: 0.0698\n",
            "Epoch 166/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 6.8547e-04\n",
            "Epoch 166: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9582 - loss: 0.0621 - val_binary_accuracy: 0.9850 - val_loss: 0.0725\n",
            "Epoch 167/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9375 - loss: 0.0493\n",
            "Epoch 167: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9354 - loss: 0.0819 - val_binary_accuracy: 0.9850 - val_loss: 0.0734\n",
            "Epoch 168/200\n",
            "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9422 - loss: 0.0795 \n",
            "Epoch 168: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9420 - loss: 0.0801 - val_binary_accuracy: 0.9887 - val_loss: 0.0689\n",
            "Epoch 169/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0590\n",
            "Epoch 169: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9454 - loss: 0.0797 - val_binary_accuracy: 0.9850 - val_loss: 0.0678\n",
            "Epoch 170/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9688 - loss: 0.0246\n",
            "Epoch 170: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9525 - loss: 0.0647 - val_binary_accuracy: 0.9850 - val_loss: 0.0722\n",
            "Epoch 171/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.0909\n",
            "Epoch 171: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9370 - loss: 0.0851 - val_binary_accuracy: 0.9850 - val_loss: 0.0681\n",
            "Epoch 172/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.0684\n",
            "Epoch 172: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9532 - loss: 0.0659 - val_binary_accuracy: 0.9850 - val_loss: 0.0713\n",
            "Epoch 173/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 1.0000 - loss: 0.0799\n",
            "Epoch 173: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9580 - loss: 0.0711 - val_binary_accuracy: 0.9887 - val_loss: 0.0703\n",
            "Epoch 174/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0234\n",
            "Epoch 174: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9602 - loss: 0.0614 - val_binary_accuracy: 0.9850 - val_loss: 0.0568\n",
            "Epoch 175/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0248\n",
            "Epoch 175: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9621 - loss: 0.0575 - val_binary_accuracy: 0.9887 - val_loss: 0.0600\n",
            "Epoch 176/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0404\n",
            "Epoch 176: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9607 - loss: 0.0777 - val_binary_accuracy: 0.9925 - val_loss: 0.0485\n",
            "Epoch 177/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0638\n",
            "Epoch 177: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9625 - loss: 0.0590 - val_binary_accuracy: 0.9887 - val_loss: 0.0389\n",
            "Epoch 178/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - binary_accuracy: 0.9688 - loss: 0.1053\n",
            "Epoch 178: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9500 - loss: 0.0821 - val_binary_accuracy: 0.9925 - val_loss: 0.0402\n",
            "Epoch 179/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9375 - loss: 0.0880\n",
            "Epoch 179: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9502 - loss: 0.0889 - val_binary_accuracy: 0.9925 - val_loss: 0.0395\n",
            "Epoch 180/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0447\n",
            "Epoch 180: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9565 - loss: 0.0640 - val_binary_accuracy: 0.9925 - val_loss: 0.0408\n",
            "Epoch 181/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.8750 - loss: 0.1146\n",
            "Epoch 181: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9441 - loss: 0.0819 - val_binary_accuracy: 0.9887 - val_loss: 0.0373\n",
            "Epoch 182/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9062 - loss: 0.0930\n",
            "Epoch 182: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9443 - loss: 0.0830 - val_binary_accuracy: 0.9887 - val_loss: 0.0398\n",
            "Epoch 183/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.1268\n",
            "Epoch 183: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9510 - loss: 0.0869 - val_binary_accuracy: 0.9887 - val_loss: 0.0455\n",
            "Epoch 184/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.1083\n",
            "Epoch 184: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9544 - loss: 0.0702 - val_binary_accuracy: 0.9887 - val_loss: 0.0463\n",
            "Epoch 185/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0210\n",
            "Epoch 185: loss did not improve from 0.06272\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9594 - loss: 0.0645 - val_binary_accuracy: 0.9887 - val_loss: 0.0499\n",
            "Epoch 186/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - binary_accuracy: 0.9062 - loss: 0.1517\n",
            "Epoch 186: loss improved from 0.06272 to 0.06072, saving model to best_model.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9556 - loss: 0.0694 - val_binary_accuracy: 0.9887 - val_loss: 0.0552\n",
            "Epoch 187/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9688 - loss: 0.0933\n",
            "Epoch 187: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9591 - loss: 0.0703 - val_binary_accuracy: 0.9887 - val_loss: 0.0456\n",
            "Epoch 188/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9062 - loss: 0.1306\n",
            "Epoch 188: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9450 - loss: 0.0788 - val_binary_accuracy: 0.9887 - val_loss: 0.0447\n",
            "Epoch 189/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9688 - loss: 0.1245\n",
            "Epoch 189: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9527 - loss: 0.0820 - val_binary_accuracy: 0.9887 - val_loss: 0.0505\n",
            "Epoch 190/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 0.9375 - loss: 0.1085\n",
            "Epoch 190: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9382 - loss: 0.0837 - val_binary_accuracy: 0.9887 - val_loss: 0.0510\n",
            "Epoch 191/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9688 - loss: 0.0234\n",
            "Epoch 191: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9604 - loss: 0.0757 - val_binary_accuracy: 0.9850 - val_loss: 0.0548\n",
            "Epoch 192/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.0680\n",
            "Epoch 192: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9550 - loss: 0.0613 - val_binary_accuracy: 0.9812 - val_loss: 0.0648\n",
            "Epoch 193/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9062 - loss: 0.1108\n",
            "Epoch 193: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9443 - loss: 0.0739 - val_binary_accuracy: 0.9812 - val_loss: 0.0691\n",
            "Epoch 194/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 0.0212\n",
            "Epoch 194: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9586 - loss: 0.0749 - val_binary_accuracy: 0.9850 - val_loss: 0.0670\n",
            "Epoch 195/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9375 - loss: 0.1760\n",
            "Epoch 195: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9558 - loss: 0.0750 - val_binary_accuracy: 0.9850 - val_loss: 0.0651\n",
            "Epoch 196/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - binary_accuracy: 0.9062 - loss: 0.1094\n",
            "Epoch 196: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9370 - loss: 0.1002 - val_binary_accuracy: 0.9925 - val_loss: 0.0372\n",
            "Epoch 197/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - binary_accuracy: 0.9375 - loss: 0.0669\n",
            "Epoch 197: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9549 - loss: 0.0741 - val_binary_accuracy: 0.9887 - val_loss: 0.0456\n",
            "Epoch 198/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9375 - loss: 0.0671\n",
            "Epoch 198: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9426 - loss: 0.0837 - val_binary_accuracy: 0.9887 - val_loss: 0.0400\n",
            "Epoch 199/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 0.9062 - loss: 0.1113\n",
            "Epoch 199: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9433 - loss: 0.0829 - val_binary_accuracy: 0.9925 - val_loss: 0.0405\n",
            "Epoch 200/200\n",
            "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - binary_accuracy: 0.9062 - loss: 0.0708\n",
            "Epoch 200: loss did not improve from 0.06072\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9505 - loss: 0.0736 - val_binary_accuracy: 0.9887 - val_loss: 0.0445\n"
          ]
        }
      ],
      "source": [
        "mc = callbacks.ModelCheckpoint('best_model.keras', monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['binary_accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=200, shuffle=True, batch_size=32, verbose=1, validation_data=(X_test, y_test), callbacks=mc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make some plots to see how our training went"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9LG6fiue2rgx",
        "outputId": "09d96543-0ce0-4111-fcbb-70f43a1d677d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training', 'Testing'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "h1AEgj0l2tdL",
        "outputId": "ba180472-298e-4af7-f06f-e95ab9f3fd21"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training', 'Testing'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So far, so good! It's a little unusual to see a training accuracy _lower_ than the testing accuracy, but this happens due to our use of Dropout. Our small dataset may also play a part in this, as the training set may have more difficult samples than the testing set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's load our best model and evaluate its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ctFdmyJB7foy"
      },
      "outputs": [],
      "source": [
        "test_features = X_test\n",
        "test_labels = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njMCwlbu2-Vv",
        "outputId": "551cb592-91f8-4d16-c66f-01df3a17e07d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 - 0s - 27ms/step - binary_accuracy: 0.9887 - loss: 0.0552\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.05518693849444389, 0.9887217879295349]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "saved_model = tf.keras.models.load_model(\"best_model.keras\")\n",
        "saved_model.evaluate(test_features, test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Over 98% accuracy! Pretty good performance, given our small dataset and simple MLP model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot our model's Confusion Matrix to analyse the performance for each class separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IsFlcm2ny5SC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "LKVByK0vy8gi",
        "outputId": "137b418a-3f07-45ce-d149-143e0b4c5e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_predictions = np.round(saved_model.predict(test_features))\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, test_predictions, values_format= '.1%', normalize=\"true\", display_labels=[\"Noise\", \"Event\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "zO0QmFwezwtY",
        "outputId": "7ef47b80-0203-4339-d98f-f9741c868ea7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(test_labels, test_predictions, display_labels=[\"Noise\", \"Event\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because this is a binary classification task, we have the false negative (miss rate) in the upper right corner, and the false positive (false alarm) rate in the lower left corner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training our model, we need to quantize it for execution on the ESP32, transforming its weights and activations from floats to 8-bit integers. We will use the [LiteRT library](https://ai.google.dev/edge/litert/models/post_training_integer_quant) for this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before quantizing, let's define a function to evaluate our model after quantization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "O2PujvegEnwr"
      },
      "outputs": [],
      "source": [
        "def evaluate(interpreter):\n",
        "    prediction = []\n",
        "    #prediction_quantized = []\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    input_format = interpreter.get_output_details()[0]['dtype']\n",
        "    input_details = interpreter.get_input_details()[0]\n",
        "\n",
        "    for i, x in enumerate(X_test):\n",
        "        if i % 100 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "\n",
        "        # Quantize the input to uint8\n",
        "        if input_details['dtype'] == np.uint8:\n",
        "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "            quant_x = x / input_scale + input_zero_point\n",
        "\n",
        "        quant_x = np.expand_dims(quant_x, axis=0).astype(input_format)\n",
        "\n",
        "        interpreter.set_tensor(input_index, quant_x)\n",
        "\n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Gather and dequantize output\n",
        "        output = interpreter.tensor(output_index)\n",
        "        predicted_label = np.round(output()[0]/255)\n",
        "\n",
        "        # Print model inputs and outputs only once\n",
        "        if i == 0:\n",
        "            print(\"Non-quantized input:\")\n",
        "            print(x)\n",
        "            print(\"Quantized input: \")\n",
        "            print(x)\n",
        "            print(\"Quantized output:\")\n",
        "            print(output()[0])\n",
        "            print(\"De-quantized output:\")\n",
        "            print(predicted_label)\n",
        "\n",
        "\n",
        "        prediction.append(predicted_label)\n",
        "\n",
        "    print('\\n')\n",
        "    # Comparing prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction = np.array(prediction)\n",
        "    #prediction_quantized = np.array(prediction_quantized)\n",
        "    accuracy = (prediction == y_test).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INT8 post-training quantization requires a representative dataset. We will use 100 samples from our training set for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gX7TN3GOEsog"
      },
      "outputs": [],
      "source": [
        "# Defining the representative dataset from the testing data\n",
        "def representative_data_gen():\n",
        "    for data in tf.data.Dataset.from_tensor_slices((X_test)).batch(1).take(100):\n",
        "        #yield [tf.dtypes.cast(data, tf.float32)]\n",
        "        yield [tf.dtypes.cast(data, tf.float32)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load our previously trained model and quantize it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IOx96McfEu9j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\samuk\\AppData\\Local\\Temp\\tmp_5hey9bv\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\samuk\\AppData\\Local\\Temp\\tmp_5hey9bv\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\samuk\\AppData\\Local\\Temp\\tmp_5hey9bv'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2392409373392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409362448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409373584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409371856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409372624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409370704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409371472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409369360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409369552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392409370896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392410260304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392410261648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392410259920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2392410262800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\samuk\\anaconda3\\envs\\sbrc\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Our converter\n",
        "model_to_convert = tf.keras.models.load_model(\"best_model.keras\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_to_convert)\n",
        "\n",
        "# Set the representative dataset for post-training quantization.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Using Integer Quantization.\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Setting the input and output tensors to uint8.\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "# Converting the model\n",
        "int_quant_model = converter.convert()\n",
        "\n",
        "# Saving the Integer Quantized TF Lite model.\n",
        "with open('int8_quant_mlp.tflite', 'wb') as f:\n",
        "    f.write(int_quant_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's evaluate our model performance after quantization. Our evaluator will print both inputs and outputs before and after quantization, just to illustrate how the process works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHR2qSk1Ex2r",
        "outputId": "c5757e39-5f8d-4c86-cdba-2f17ff935ac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Non-quantized input:\n",
            "[ 62.364 -11.65  -24.387 -14.616   0.821  12.287   1.48   -7.877  -0.348\n",
            "  -0.911   0.792   0.339   1.368   1.802   1.056  -0.108  -1.011  -0.823\n",
            "   0.381  -2.822   1.313  -0.457  -1.102   0.009   0.799  -0.167   0.863\n",
            "   0.13   -1.642   0.869   0.132   0.448   0.03   -0.493  -0.025  -0.261\n",
            "   1.968  -0.259   1.504   0.063  -1.455   0.34 ]\n",
            "Quantized input: \n",
            "[ 62.364 -11.65  -24.387 -14.616   0.821  12.287   1.48   -7.877  -0.348\n",
            "  -0.911   0.792   0.339   1.368   1.802   1.056  -0.108  -1.011  -0.823\n",
            "   0.381  -2.822   1.313  -0.457  -1.102   0.009   0.799  -0.167   0.863\n",
            "   0.13   -1.642   0.869   0.132   0.448   0.03   -0.493  -0.025  -0.261\n",
            "   1.968  -0.259   1.504   0.063  -1.455   0.34 ]\n",
            "Quantized output:\n",
            "[255]\n",
            "De-quantized output:\n",
            "[1.]\n",
            "Evaluated on 100 results so far.\n",
            "Evaluated on 200 results so far.\n",
            "\n",
            "\n",
            "Quantized TFLite Model Test Accuracy: 93.98496240601504\n"
          ]
        }
      ],
      "source": [
        "# Passing the Int8 TF Lite model to the interpreter.\n",
        "interpreter = tf.lite.Interpreter('int8_quant_mlp.tflite')\n",
        "\n",
        "# Allocating tensors.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Evaluating the model on the test dataset.\n",
        "test_accuracy_quant = evaluate(interpreter)\n",
        "\n",
        "# Printing the test accuracy for the FP-16 quantized TFLite model and the baseline Keras model.\n",
        "print('Quantized TFLite Model Test Accuracy:', test_accuracy_quant*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Over 90% accuracy! It's gone down from our non-quantized model, but it's still good enough for our application. Let's take a final look at our model before converting it for the ESP32:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNW-CMIyEPfA",
        "outputId": "6918eee7-3305-4020-9ce8-bd39e146d1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== int8_quant_mlp.tflite ===\n",
            "\n",
            "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
            "T# represents the Tensor numbers. For example, in Subgraph#0, the QUANTIZE op takes\n",
            "tensor #0 as input and produces tensor #15 as output.\n",
            "\n",
            "Subgraph#0 main(T#0) -> [T#24]\n",
            "  Op#0 QUANTIZE(T#0) -> [T#15]\n",
            "  Op#1 FULLY_CONNECTED(T#15, T#14, T#13[13, -12, -34, -104, -56, ...]) -> [T#16]\n",
            "  Op#2 FULLY_CONNECTED(T#16, T#12, T#11[-102, -254, 373, -501, -412, ...]) -> [T#17]\n",
            "  Op#3 FULLY_CONNECTED(T#17, T#10, T#9[169, -240, -274, -206, -341, ...]) -> [T#18]\n",
            "  Op#4 FULLY_CONNECTED(T#18, T#8, T#7[-353, 309, -145, -80, -166, ...]) -> [T#19]\n",
            "  Op#5 FULLY_CONNECTED(T#19, T#6, T#5[-109, -155, 305, -113]) -> [T#20]\n",
            "  Op#6 FULLY_CONNECTED(T#20, T#4, T#3[216, -35]) -> [T#21]\n",
            "  Op#7 FULLY_CONNECTED(T#21, T#2, T#1[-8]) -> [T#22]\n",
            "  Op#8 LOGISTIC(T#22) -> [T#23]\n",
            "  Op#9 QUANTIZE(T#23) -> [T#24]\n",
            "\n",
            "Tensors of Subgraph#0\n",
            "  T#0(serving_default_input_layer:0) shape_signature:[-1, 42], type:UINT8\n",
            "  T#1(tfl.pseudo_qconst) shape:[1], type:INT32 RO 4 bytes, buffer: 2, data:[-8]\n",
            "  T#2(tfl.pseudo_qconst1) shape:[1, 2], type:INT8 RO 2 bytes, buffer: 3, data:[., 6]\n",
            "  T#3(tfl.pseudo_qconst2) shape:[2], type:INT32 RO 8 bytes, buffer: 4, data:[216, -35]\n",
            "  T#4(tfl.pseudo_qconst3) shape:[2, 4], type:INT8 RO 8 bytes, buffer: 5, data:[., ., ., ., P, ...]\n",
            "  T#5(tfl.pseudo_qconst4) shape:[4], type:INT32 RO 16 bytes, buffer: 6, data:[-109, -155, 305, -113]\n",
            "  T#6(tfl.pseudo_qconst5) shape:[4, 8], type:INT8 RO 32 bytes, buffer: 7, data:[R, ., ,, >, (, ...]\n",
            "  T#7(tfl.pseudo_qconst6) shape:[8], type:INT32 RO 32 bytes, buffer: 8, data:[-353, 309, -145, -80, -166, ...]\n",
            "  T#8(tfl.pseudo_qconst7) shape:[8, 16], type:INT8 RO 128 bytes, buffer: 9, data:[., ., z, ., ., ...]\n",
            "  T#9(tfl.pseudo_qconst8) shape:[16], type:INT32 RO 64 bytes, buffer: 10, data:[169, -240, -274, -206, -341, ...]\n",
            "  T#10(tfl.pseudo_qconst9) shape:[16, 32], type:INT8 RO 512 bytes, buffer: 11, data:[., ., ., /, ., ...]\n",
            "  T#11(tfl.pseudo_qconst10) shape:[32], type:INT32 RO 128 bytes, buffer: 12, data:[-102, -254, 373, -501, -412, ...]\n",
            "  T#12(tfl.pseudo_qconst11) shape:[32, 42], type:INT8 RO 1344 bytes, buffer: 13, data:[., >, 7, ., ., ...]\n",
            "  T#13(tfl.pseudo_qconst12) shape:[42], type:INT32 RO 168 bytes, buffer: 14, data:[13, -12, -34, -104, -56, ...]\n",
            "  T#14(tfl.pseudo_qconst13) shape:[42, 42], type:INT8 RO 1764 bytes, buffer: 15, data:[., M, q, ., G, ...]\n",
            "  T#15(tfl.quantize) shape_signature:[-1, 42], type:INT8\n",
            "  T#16(sequential_1/dense_1/MatMul;sequential_1/dense_1/Relu;sequential_1/dense_1/BiasAdd) shape_signature:[-1, 42], type:INT8\n",
            "  T#17(sequential_1/dense_1_2/MatMul;sequential_1/dense_1_2/Relu;sequential_1/dense_1_2/BiasAdd) shape_signature:[-1, 32], type:INT8\n",
            "  T#18(sequential_1/dense_2_1/MatMul;sequential_1/dense_2_1/Relu;sequential_1/dense_2_1/BiasAdd) shape_signature:[-1, 16], type:INT8\n",
            "  T#19(sequential_1/dense_3_1/MatMul;sequential_1/dense_3_1/Relu;sequential_1/dense_3_1/BiasAdd) shape_signature:[-1, 8], type:INT8\n",
            "  T#20(sequential_1/dense_4_1/MatMul;sequential_1/dense_4_1/Relu;sequential_1/dense_4_1/BiasAdd) shape_signature:[-1, 4], type:INT8\n",
            "  T#21(sequential_1/dense_5_1/MatMul;sequential_1/dense_5_1/Relu;sequential_1/dense_5_1/BiasAdd) shape_signature:[-1, 2], type:INT8\n",
            "  T#22(sequential_1/dense_6_1/MatMul;sequential_1/dense_6_1/Add) shape_signature:[-1, 1], type:INT8\n",
            "  T#23(StatefulPartitionedCall_1:01) shape_signature:[-1, 1], type:INT8\n",
            "  T#24(StatefulPartitionedCall_1:0) shape_signature:[-1, 1], type:UINT8\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Your TFLite model has '1' signature_def(s).\n",
            "\n",
            "Signature#0 key: 'serving_default'\n",
            "- Subgraph: Subgraph#0\n",
            "- Inputs: \n",
            "    'input_layer' : T#0\n",
            "- Outputs: \n",
            "    'output_0' : T#24\n",
            "\n",
            "---------------------------------------------------------------\n",
            "              Model size:      11368 bytes\n",
            "    Non-data buffer size:       7030 bytes (61.84 %)\n",
            "  Total data buffer size:       4338 bytes (38.16 %)\n",
            "    (Zero value buffers):         16 bytes (00.14 %)\n",
            "\n",
            "* Buffers of TFLite model are mostly used for constant tensors.\n",
            "  And zero value buffers are buffers filled with zeros.\n",
            "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
            "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tf.lite.experimental.Analyzer.analyze(model_path=\"int8_quant_mlp.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting the model to C data array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to convert our quantized .tflite model to a C data array format that can be easily loaded and interpreted in the ESP32. We use this helper function to convert it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1BDEGFsuEm9-"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "def convert_bytes_to_c_source(data,\n",
        "                              array_name,\n",
        "                              max_line_width=80,\n",
        "                              include_guard=None,\n",
        "                              include_path=None,\n",
        "                              use_tensorflow_license=False):\n",
        "  \"\"\"Returns strings representing a C constant array containing `data`.\n",
        "\n",
        "  Args:\n",
        "    data: Byte array that will be converted into a C constant.\n",
        "    array_name: String to use as the variable name for the constant array.\n",
        "    max_line_width: The longest line length, for formatting purposes.\n",
        "    include_guard: Name to use for the include guard macro definition.\n",
        "    include_path: Optional path to include in the source file.\n",
        "    use_tensorflow_license: Whether to include the standard TensorFlow Apache2\n",
        "      license in the generated files.\n",
        "\n",
        "  Returns:\n",
        "    Text that can be compiled as a C source file to link in the data as a\n",
        "    literal array of values.\n",
        "    Text that can be used as a C header file to reference the literal array.\n",
        "  \"\"\"\n",
        "\n",
        "  starting_pad = \"   \"\n",
        "  array_lines = []\n",
        "  array_line = starting_pad\n",
        "  for value in bytearray(data):\n",
        "    if (len(array_line) + 4) > max_line_width:\n",
        "      array_lines.append(array_line + \"\\n\")\n",
        "      array_line = starting_pad\n",
        "    array_line += \" 0x%02x,\" % (value,)\n",
        "  if len(array_line) > len(starting_pad):\n",
        "    array_lines.append(array_line + \"\\n\")\n",
        "  array_values = \"\".join(array_lines)\n",
        "\n",
        "  if include_guard is None:\n",
        "    include_guard = \"TENSORFLOW_LITE_UTIL_\" + array_name.upper() + \"_DATA_H_\"\n",
        "\n",
        "  if include_path is not None:\n",
        "    include_line = \"#include \\\"{include_path}\\\"\\n\".format(\n",
        "        include_path=include_path)\n",
        "  else:\n",
        "    include_line = \"\"\n",
        "\n",
        "  if use_tensorflow_license:\n",
        "    license_text = \"\"\"\n",
        "/* Copyright {year} The TensorFlow Authors. All Rights Reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "==============================================================================*/\n",
        "\"\"\".format(year=datetime.date.today().year)\n",
        "  else:\n",
        "    license_text = \"\"\n",
        "\n",
        "  source_template = \"\"\"{license_text}\n",
        "// This is a TensorFlow Lite model file that has been converted into a C data\n",
        "// array using the tensorflow.lite.util.convert_bytes_to_c_source() function.\n",
        "// This form is useful for compiling into a binary for devices that don't have a\n",
        "// file system.\n",
        "\n",
        "{include_line}\n",
        "#include \"model.h\"\n",
        "\n",
        "alignas(8) const unsigned char {array_name}[] = {{\n",
        "{array_values}}};\n",
        "const int {array_name}_len = {array_length};\n",
        "\"\"\"\n",
        "\n",
        "  source_text = source_template.format(\n",
        "      array_name=array_name,\n",
        "      array_length=len(data),\n",
        "      array_values=array_values,\n",
        "      license_text=license_text,\n",
        "      include_line=include_line)\n",
        "\n",
        "  header_template = \"\"\"\n",
        "{license_text}\n",
        "\n",
        "// This is a TensorFlow Lite model file that has been converted into a C data\n",
        "// array using the tensorflow.lite.util.convert_bytes_to_c_source() function.\n",
        "// This form is useful for compiling into a binary for devices that don't have a\n",
        "// file system.\n",
        "\n",
        "#ifndef {include_guard}\n",
        "#define {include_guard}\n",
        "\n",
        "extern const unsigned char {array_name}[];\n",
        "extern const int {array_name}_len;\n",
        "\n",
        "#endif  // {include_guard}\n",
        "\"\"\"\n",
        "\n",
        "  header_text = header_template.format(\n",
        "      array_name=array_name,\n",
        "      include_guard=include_guard,\n",
        "      license_text=license_text)\n",
        "\n",
        "  return source_text, header_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('int8_quant_mlp.tflite', 'rb') as f:\n",
        "    bytes_data = f.read()\n",
        "    source_text, source_header = convert_bytes_to_c_source(bytes_data, \"g_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('model.cc', 'w') as f:\n",
        "    f.write(source_text)\n",
        "\n",
        "with open('model.h', 'w') as f:\n",
        "    f.write(source_header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're all set! Now our model is saved at ```model.cc``` and ```model.h``` in a format suitable for use in the ESP32. If you made modifications to the models or the feature engineering process, remember to copy and pastecboth files, as well as the ```preprocessing.cc``` and ```preprocessing.h``` to the ```OnboardInference``` folder."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sbrc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
